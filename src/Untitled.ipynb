{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "\n",
    "\n",
    "#入力画像の処理を行う\n",
    "#訓練時と推論時で処理が異なる\n",
    "\n",
    "class ImageTransform():\n",
    "    \"\"\"\n",
    "    画像の前処理クラス。\n",
    "    画像のサイズをリサイズ\n",
    "    resize: int\n",
    "        リサイズ先の画像の大きさ\n",
    "    mean : (RGB)\n",
    "    std:(RGB)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resize):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                 transforms.CenterCrop(28),\n",
    "                # transforms.RandomRotation(degrees=20), #ランダムに回転\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                transforms.CenterCrop(28),\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        \"\"\"\n",
    "        pahes:'train' or 'val'\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)\n",
    "\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    '''\n",
    "    file_list : リスト\n",
    "        画像パス\n",
    "    transform: object\n",
    "        前処理クラスのインスタンス\n",
    "    phase : 学習化テストか設定する\n",
    "    '''\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.transform = transform#前処理クラスのリスト\n",
    "        self.file_list = file_list#ファイルパスのリスト\n",
    "        self.phase = phase#train or val の指定\n",
    "\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のTensor形式のデータとラベルの取得\n",
    "        '''\n",
    "        #index番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        t_data = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        t_data.paste(img, mask=img.split()[3])\n",
    "        if t_data.mode == \"RGB\":\n",
    "            t_data = t_data.convert(\"L\")\n",
    "\n",
    "        #画像の前処理実施\n",
    "        img_transformed = self.transform(\n",
    "            t_data, self.phase\n",
    "        )\n",
    "\n",
    "        #画像のラベルをファイル名から抜き出す\n",
    "        if self.phase == \"train\":\n",
    "            label = int(img_path[19])\n",
    "        elif self.phase == \"val\":\n",
    "            label = int(img_path[len(os.getcwd()) + 24])\n",
    "        label = torch.tensor(label, dtype=torch.int64)\n",
    "        return img_transformed, label\n",
    "\n",
    "class testDataset(data.Dataset):\n",
    "    '''\n",
    "    file_list : リスト\n",
    "        画像パス\n",
    "    transform: object\n",
    "        前処理クラスのインスタンス\n",
    "    phase : 学習化テストか設定する\n",
    "    '''\n",
    "    def __init__(self,transform=None, phase='train'):\n",
    "\n",
    "        self.transform = transform#前処理クラスのリスト\n",
    "        self.phase = phase#train or val の指定\n",
    "\n",
    "        rootpath = \"./訓練用画像/\"\n",
    "        target_path = osp.join(rootpath+'tests/*.png')\n",
    "        \n",
    "        path_list = []\n",
    "\n",
    "        for path in glob.glob(target_path):\n",
    "            path_list.append(path)\n",
    "\n",
    "        self.file_list = path_list\n",
    "\n",
    "        self.label_dict = {}\n",
    "\n",
    "        with open('訓練用画像/tests.txt') as f:\n",
    "            for line in f:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                name, label = line.split(\"/\")\n",
    "                self.label_dict[name] = int(label)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のTensor形式のデータとラベルの取得\n",
    "        '''\n",
    "        #index番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        file_name = img_path[14:]\n",
    "        label = self.label_dict[file_name]\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        t_data = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        t_data.paste(img, mask=img.split()[3])\n",
    "        if t_data.mode == \"RGB\":\n",
    "            t_data = t_data.convert(\"L\")\n",
    "        #画像の前処理実施\n",
    "        img_transformed = self.transform(\n",
    "            t_data, self.phase\n",
    "        )\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.int64)\n",
    "        return img_transformed, label\n",
    "\n",
    "\n",
    "\n",
    "class make_datapath_list():\n",
    "\n",
    "    def _make_datapath_list(ph):\n",
    "        \"\"\"\n",
    "        データパスを格納したリストを作成する\n",
    "        \"\"\"\n",
    "\n",
    "        rootpath = os.getcwd() + \"/src/訓練用画像/\" + ph + \"/\"\n",
    "        target_path = osp.join(rootpath+'**/*.png')\n",
    "    \n",
    "        path_list = []\n",
    "\n",
    "        for path in glob.glob(target_path):\n",
    "            path_list.append(path)\n",
    "\n",
    "        return path_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import QMNIST\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Dropout2d(p=0.20)\n",
    "            )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.25),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            #全結合層\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             #全結合層\n",
    "#             nn.Linear(15488, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Dropout(p=0.2),\n",
    "#             nn.Linear(128, 10)\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):  \n",
    "\n",
    "        out = self.cnn1(x)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.cnn3(out)\n",
    "\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    #初期設定\n",
    "    #GPUが使えるか確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス\", device)\n",
    "    #モデルをGPUへ\n",
    "    net.to(device)\n",
    "    #ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        #epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train() #モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval() #モデルを検証モードに\n",
    "            epoch_loss = 0.0 #epochの損失0\n",
    "            epoch_corrects = 0 #epochの正解数\n",
    "            #データローダーからミニバッチを取り出すループ\n",
    "            for inputs, labels in tqdm.tqdm(dataloders_dict[phase]):\n",
    "                #optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #順伝搬(forward)計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)#損失を計算\n",
    "                    _, preds = torch.max(outputs, 1) #ラベルを予測\n",
    "                    #訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    #イテレーション結果の計算\n",
    "                    #lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    #正解の合計数を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            #epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloders_dict[phase].dataset)\n",
    "            print('{} Loss:{:.4f} Acc: {:.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "            if phase == 'train':\n",
    "                train_acc_list.append(epoch_acc)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "            else:\n",
    "                val_acc_list.append(epoch_acc)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "    return val_loss_list,train_loss_list, val_acc_list, train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス cuda:0\n",
      "Epoch 1/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:08<00:00, 69.12it/s]\n",
      " 19%|███████████████▌                                                                   | 6/32 [00:00<00:00, 55.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss:1.7840 Acc: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 56.74it/s]\n",
      "  0%|                                                                                          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss:2.3472 Acc: 0.1110\n",
      "Epoch 2/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                          | 51/600 [00:01<01:03,  8.58it/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)  \n",
    "np.random.seed(seed)  \n",
    "# PyTorch のRNGを初期化  \n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(32),\n",
    "     transforms.RandomCrop(28),\n",
    "     transforms.RandomRotation(degrees=20),\n",
    "     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))\n",
    "     ])\n",
    "\n",
    "\n",
    "trainset = QMNIST(root='./',\n",
    "                 train=True,\n",
    "                 download=True,\n",
    "                 transform=transform)\n",
    "testset = QMNIST(root='./',\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)\n",
    "testloader = DataLoader(testset,\n",
    "                        batch_size=100,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2)\n",
    "\n",
    "train_list = make_datapath_list._make_datapath_list(\"tranings\")\n",
    "\n",
    "test_dataset = MyDataset(file_list = train_list, transform=ImageTransform(32),phase='val')\n",
    "test_dataloder = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle=False)\n",
    "\n",
    "\n",
    "dataloders_dict = {\"train\": trainloader, \"val\": test_dataloder}\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.006)\n",
    "\n",
    "val_loss, train_loss, val_acc, train_acc = train_model(model, dataloders_dict, criterion, optimizer, num_epochs=10)\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"os.path.dirname(__file__)                 : %r\" % (os.path.dirname(__file__)))\n",
    "print(\"os.path.abspath(__file__)                 : %r\" % (os.path.abspath(__file__)))\n",
    "print(\"os.path.dirname(os.path.abspath(__file__)): %r\" % (os.path.dirname(os.path.abspath(__file__))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getcwd:       C:\\Users\\瀧川秀明\\Workspase\\ssi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4cfb4840b005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'getcwd:      '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__file__:    '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('getcwd:      ', os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
