{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import QMNIST\n",
    "# from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from statistics import median, mean, stdev\n",
    "from datetime import timedelta\n",
    "from contextlib import ContextDecorator\n",
    "def benchmark(niter=1, duration=None, batch_size=1):\n",
    "    \n",
    "    if duration is not None:\n",
    "        if not isinstance(duration, (int, float, timedelta)):\n",
    "            raise TypeError(f\"'duration' must be int, float or timedelta, not '{type(duration).__name__}'.\")\n",
    "        if isinstance(duration, timedelta):\n",
    "            duration = duration.total_seconds()\n",
    "    def decorator(func):\n",
    "        def wrapped(*args, **kwargs):\n",
    "            start_time = time.perf_counter()\n",
    "            exec_time = 0\n",
    "            iteration = 0\n",
    "            \n",
    "            bench = Benchmark(batch_size=batch_size)\n",
    "            while (niter and iteration < niter) or (duration and exec_time < duration):\n",
    "                with bench:\n",
    "                    func(*args, **kwargs)\n",
    "                iteration += 1\n",
    "                exec_time = (time.perf_counter() - start_time)\n",
    "                \n",
    "            print(bench)\n",
    "            \n",
    "        return wrapped\n",
    "    return decorator\n",
    "class Benchmark(ContextDecorator):\n",
    "    \n",
    "    def __init__(self, out=False, batch_size=1):\n",
    "        self.start_time = None\n",
    "        self.lap_time = None\n",
    "        self.end_time = None\n",
    "        self.times = []\n",
    "        self.batch_size = batch_size\n",
    "        self.out = out\n",
    "    \n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end_time:\n",
    "            return timedelta(seconds=(self.end_time - self.start_time))\n",
    "        else:\n",
    "            return timedelta()\n",
    "    \n",
    "    def __str__(self):\n",
    "        if len(self.times) == 0:\n",
    "            return super().__str__()\n",
    "        \n",
    "        iteration = len(self.times)\n",
    "        total_duration = self.duration\n",
    "        \n",
    "        if iteration > 1:\n",
    "            latency_s    = median(self.times)\n",
    "            latency_mean = mean(self.times)\n",
    "            latency_std  = stdev(self.times)\n",
    "        else:\n",
    "            latency_s    = latency_mean = self.times[0]\n",
    "            latency_std  = 0.0\n",
    "            \n",
    "        fps = self.batch_size * 1 / latency_s\n",
    "        \n",
    "        output = [\n",
    "            f\"Count:      {iteration:,} iteration(s)\",\n",
    "            f\"Duration:   {total_duration}\",\n",
    "            f\"Latency:    {_format_time(latency_s)} ({_format_time(latency_mean)} ± {_format_time(latency_std)})\", \n",
    "            f\"Throughput: {fps:.2f} FPS\",\n",
    "        ]\n",
    "        return str.join('\\n', output)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        if self.lap_time:\n",
    "            raise RuntimeError(\"Nested transactions are not supported.\")\n",
    "        \n",
    "        t = time.perf_counter()\n",
    "        if not self.start_time:\n",
    "            self.start_time = t\n",
    "        self.lap_time = t\n",
    "        return self\n",
    "    def __exit__(self, *exc):\n",
    "        t = time.perf_counter()\n",
    "        self.end_time = t\n",
    "        \n",
    "        elapsed = (t - self.lap_time)\n",
    "        self.lap_time = None\n",
    "        self.times.append(elapsed)\n",
    "        \n",
    "        if self.out:\n",
    "            print(self)\n",
    "        \n",
    "        return False\n",
    "\n",
    "def _format_time(timespan, precision=2):\n",
    "    import math\n",
    "\n",
    "    if isinstance(timespan, timedelta):\n",
    "        timespan = timespan.total_seconds()\n",
    "\n",
    "    if timespan >= 60.0:\n",
    "        # Idea from http://snipplr.com/view/5713/\n",
    "        parts = [(\"days\", 3600*24), (\"h\", 3600), (\"m\", 60), (\"s\", 1)]\n",
    "        time = []\n",
    "        leftover = timespan\n",
    "        for (suffix, length) in parts:\n",
    "            value = int(leftover / length)\n",
    "            if value > 0:\n",
    "                leftover = leftover % length\n",
    "                time.append(f\"{value} {suffix}\")\n",
    "            if leftover < 1:\n",
    "                break\n",
    "        return \" \".join(time)\n",
    "\n",
    "    units = [\"s\", \"ms\", \"us\",\"ns\"]\n",
    "    scale = [1, 1e3, 1e6, 1e9]\n",
    "    order = min(-int(math.floor(math.log10(timespan)) // 3), 3) if timespan > 0.0 else 3\n",
    "\n",
    "    return \"%.*f %s\" % (precision, timespan * scale[order], units[order])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Dropout2d(p=0.20)\n",
    "            )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.25),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            #全結合層\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    " \n",
    "\n",
    "    def forward(self, x):  \n",
    "\n",
    "        out = self.cnn1(x)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.cnn3(out)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out, dim = 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    #初期設定\n",
    "    #GPUが使えるか確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス\", device)\n",
    "    #モデルをGPUへ\n",
    "    net.to(device)\n",
    "    #ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        #epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train() #モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval() #モデルを検証モードに\n",
    "            epoch_loss = 0.0 #epochの損失0\n",
    "            epoch_corrects = 0 #epochの正解数\n",
    "            #データローダーからミニバッチを取り出すループ\n",
    "            for inputs, labels in tqdm.tqdm(dataloders_dict[phase]):\n",
    "                #optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "                #順伝搬(forward)計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)#損失を計算\n",
    "                    _, preds = torch.max(outputs, 1) #ラベルを予測\n",
    "                    #訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    #イテレーション結果の計算\n",
    "                    #lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    #正解の合計数を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            #epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloders_dict[phase].dataset)\n",
    "            print('{} Loss:{:.4f} Acc: {:.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "            if phase == 'train':\n",
    "                train_acc_list.append(epoch_acc)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "            else:\n",
    "                val_acc_list.append(epoch_acc)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "    return val_loss_list,train_loss_list, val_acc_list, train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import os.path as osp\n",
    "import glob\n",
    "\n",
    "\n",
    "#入力画像の処理を行う\n",
    "#訓練時と推論時で処理が異なる\n",
    "\n",
    "class ImageTransform():\n",
    "\n",
    "    def __init__(self, resize):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                # transforms.RandomRotation(degrees=20), #ランダムに回転\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        \"\"\"\n",
    "        pahes:'train' or 'val'\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)\n",
    "\n",
    "class testDataset(data.Dataset):\n",
    "    '''\n",
    "    file_list : リスト\n",
    "        画像パス\n",
    "    transform: object\n",
    "        前処理クラスのインスタンス\n",
    "    phase : 学習化テストか設定する\n",
    "    '''\n",
    "    def __init__(self,transform=None, phase='val'):\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.CenterCrop(28),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, ), (0.5, ))\n",
    "                         ])\n",
    "        self.phase = phase#train or val の指定\n",
    "\n",
    "        rootpath = \"../訓練用画像/tranings/\"\n",
    "        target_path = osp.join(rootpath+'**/*.png')\n",
    "    \n",
    "        path_list = []\n",
    "\n",
    "        for path in glob.glob(target_path):\n",
    "            path_list.append(path)\n",
    "\n",
    "        self.file_list = path_list\n",
    "\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のTensor形式のデータとラベルの取得\n",
    "        '''\n",
    "        #index番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        label = img_path[18]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGBA')\n",
    "        r, g, b, a = img.split()\n",
    "        img = np.asarray(a)\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        img_transformed = self.transform(\n",
    "            img\n",
    "        )\n",
    "\n",
    "        label = torch.tensor(int(label), dtype=torch.int64)\n",
    "        \n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス cuda:0\n",
      "Epoch 1/1\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:28<00:00,  2.08it/s]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss:1.4658 Acc: 0.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss:1.5206 Acc: 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)  \n",
    "np.random.seed(seed)  \n",
    "# PyTorch のRNGを初期化  \n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "def augment(aug, image):\n",
    "    return aug(image=image)['image']\n",
    "\n",
    "def ElTransform(img):\n",
    "    \"\"\"\n",
    "    画像をゆがませる\n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    aug = albu.ElasticTransform(alpha=0.5, sigma=0, alpha_affine=0, interpolation=1, border_mode=2, p=0.5)\n",
    "    img = augment(aug, np.array(img))\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "rotation_range=10\n",
    "zoom_range = 0.10\n",
    "width_shift_range=0.1 \n",
    "height_shift_range=0.1\n",
    "train_transform = transforms.Compose([\n",
    "     transforms.Resize(32),\n",
    "     transforms.CenterCrop(28),\n",
    "     transforms.Lambda(ElTransform),\n",
    "     transforms.RandomAffine(degrees=rotation_range, translate=(width_shift_range, height_shift_range), \n",
    "    scale=(1 - zoom_range, 1 + zoom_range)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))\n",
    "     ])\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize(32)\n",
    "#      transforms.CenterCrop(28),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, ), (0.5, ))\n",
    "#      ])\n",
    "\n",
    "\n",
    "trainset = QMNIST(root='./',\n",
    "                 train=True,\n",
    "                 download=True,\n",
    "                 transform=train_transform)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=1024,\n",
    "                         shuffle=True,\n",
    "                         num_workers=0)\n",
    "testloader =  torch.utils.data.DataLoader(testDataset(), batch_size = 1000, shuffle=False)\n",
    "\n",
    "dataloders_dict = {\"train\": trainloader, \"val\": testloader}\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./mnist_cnn.pth\"))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00003)\n",
    "\n",
    "val_loss, train_loss, val_acc, train_acc = train_model(model, dataloders_dict, criterion, optimizer, num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./mnist_cnn.pth\"))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(946)\n"
     ]
    }
   ],
   "source": [
    "class valDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        path = \"../訓練用画像/tests/\"\n",
    "        self.label_dict = []\n",
    "        with open('../訓練用画像/tests.txt') as f:\n",
    "            for line in f:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                name, label = line.split(\"/\")\n",
    "                self.label_dict.append((\"../訓練用画像/tests/\" + name, int(label)))\n",
    "        self.transform = transforms.Compose([\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.CenterCrop(28),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, ), (0.5, ))\n",
    "                         ])\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.label_dict)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.label_dict[index]\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGBA')\n",
    "        r, g, b, a = img.split()\n",
    "        img = np.asarray(a)\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        img_transformed = self.transform(\n",
    "            img\n",
    "        )\n",
    "\n",
    "        label = torch.tensor(int(label), dtype=torch.int64)\n",
    "        \n",
    "        return img_transformed, label\n",
    "testloader =  torch.utils.data.DataLoader(testDataset(), batch_size = 1000, shuffle=False)\n",
    "# testloader =  torch.utils.data.DataLoader(valDataset(), batch_size = 100, shuffle=False)\n",
    "pred = []\n",
    "label = []\n",
    "for i, l in testloader:\n",
    "    i = i.to('cuda')\n",
    "    output = model(i)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    print(torch.sum(predicted.to('cpu') == l.data))\n",
    "    pred.append(predicted)\n",
    "    label.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label[0].to('cpu').numpy()\n",
    "# pred[0].to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンフュージョンマトリックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1acf386cf48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testloader =  torch.utils.data.DataLoader(valDataset(), batch_size = 100, shuffle=False)\n",
    "pred = []\n",
    "label = []\n",
    "for i, l in testloader:\n",
    "    i = i.to('cuda')\n",
    "    output = model(i)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    pred.append(predicted)\n",
    "    label.append(l)\n",
    "confusion = confusion_matrix(label[0].to('cpu').numpy(), pred[0].to('cpu').numpy())\n",
    "df_cm = pd.DataFrame(confusion,index = [i for i in \"0123456789\"],\n",
    "                  columns = [i for i in \"0123456789\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(946)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1acf54f3fc8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testloader =  torch.utils.data.DataLoader(testDataset(), batch_size = 1000, shuffle=False)\n",
    "\n",
    "pred = []\n",
    "label = []\n",
    "for i, l in testloader:\n",
    "    i = i.to('cuda')\n",
    "    output = model(i)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    pred.append(predicted)\n",
    "    print(torch.sum(predicted.to('cpu') == l.data))\n",
    "    label.append(l)\n",
    "confusion = confusion_matrix(label[0].to('cpu').numpy(), pred[0].to('cpu').numpy())\n",
    "df_cm = pd.DataFrame(confusion,index = [i for i in \"0123456789\"],\n",
    "                  columns = [i for i in \"0123456789\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベンチマーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:      100 iteration(s)\n",
      "Duration:   0:00:00.176807\n",
      "Latency:    1.12 ms (1.14 ms ± 132.06 us)\n",
      "Throughput: 892.14 FPS\n"
     ]
    }
   ],
   "source": [
    "#import Benchmark\n",
    "\n",
    "testloader =  torch.utils.data.DataLoader(testDataset(), batch_size = 1, shuffle=False)\n",
    "testloader =  torch.utils.data.DataLoader(valDataset(), batch_size = 1, shuffle=False)\n",
    "pred = []\n",
    "label = []\n",
    "model.to(\"cpu\")\n",
    "# @benchmark(duration=5)\n",
    "# def test():\n",
    "#     with torch.no_grad():\n",
    "#         for i, l in testloader:\n",
    "#             output = model(i)\n",
    "\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        bm = Benchmark(out=False)\n",
    "        for i, l in testloader:\n",
    "            with bm:\n",
    "                output = model(i)\n",
    "    print(bm)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX　export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./mnist_cnn.pth\"))\n",
    "model.to('cpu')\n",
    "x = Variable(torch.randn(1, 1, 28, 28))\n",
    "torch.onnx.export(model, x, './m.onnx', export_params=True , dynamic_axes={'input': {0: 'sequence1'}, 'output': {0: 'sequence2'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "transform = transforms.Compose([\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.CenterCrop(28),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, ), (0.5, ))\n",
    "                         ])\n",
    "model = onnx.load('./mnist.onnx')\n",
    "img_list = []\n",
    "label_list = []\n",
    "with open('../訓練用画像/tests.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        name, label = line.split(\"/\")\n",
    "        img = Image.open(\"../訓練用画像/tests/\" + name).convert('RGBA')\n",
    "        r, g, b, a = img.split()\n",
    "        \n",
    "        img = np.asarray(a)\n",
    "        img = Image.fromarray(img)\n",
    "        img = transform(img)\n",
    "        img = img.numpy()\n",
    "        img_list.append(img)\n",
    "        label_list.append(int(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img_list).astype(\"float32\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "input.1 [1, 1, 28, 28]\n",
      "output:\n",
      "43 [1, 10]\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(\"./m.onnx\")\n",
    "# 入力のラベル名の確認\n",
    "print(\"input:\")\n",
    "for session_input in session.get_inputs():\n",
    "    print(session_input.name, session_input.shape)\n",
    "# 出力のラベル名の確認\n",
    "print(\"output:\")\n",
    "for session_output in session.get_outputs():\n",
    "    print(session_output.name, session_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in np.array(img_list).astype(\"float32\"):\n",
    "    i = i[None, ...]\n",
    "    pre = session.run([session_output.name], {session_input.name: i})\n",
    "    pre = torch.tensor(pre[0], dtype=torch.float32)\n",
    "    _, out = torch.max(pre, 1)\n",
    "    pred.append(out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.1 for the following indices\n index: 0 Got: 100 Expected: 1\n Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0975d1ea7f7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msession_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msession_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\onnxruntime\\capi\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.1 for the following indices\n index: 0 Got: 100 Expected: 1\n Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "session.run([session_output.name], {session_input.name: np.array(img_list).astype(\"float32\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-2ce0119210d0>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-2ce0119210d0>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    np.array(img_list).astype(\"float32\"):\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BM = Benchmark(batch_size=1)\n",
    "\n",
    "def test():\n",
    "    with BM:\n",
    "        np.array(img_list).astype(\"float32\"):\n",
    "            i = i[None, ...]\n",
    "            pre = session.run([session_output.name], {session_input.name: i})\n",
    "    print(BM)\n",
    "#         pre = torch.tensor(pre[0], dtype=torch.float32)\n",
    "#         _, out = torch.max(pre, 1)\n",
    "#         pred.append(out.item())\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:      100 iteration(s)\n",
      "Duration:   0:00:00.015280\n",
      "Latency:    135.60 us (150.99 us ± 49.95 us)\n",
      "Throughput: 7374.63 FPS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    bm = Benchmark(out=False)\n",
    "    for i in np.array(img_list).astype(\"float32\"):\n",
    "        with bm:\n",
    "            i = i[None, ...]\n",
    "            pre = session.run([session_output.name], {session_input.name: i})\n",
    "    print(bm)\n",
    "    # 推論実行 \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "label = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAA6UlEQVR4nO3Vv0pDMRSA8Z/2glTBxQ4OvoBrURTa2ckn8LF8Cx0cXZwcpTi6uOjk4CCVIuJ/h9xScUpyaehwP8gSTvIl55ATWloWnaXIuC4OsI6feu4TV7ibw7kM8IVrjOrxhOPUjarIuBXcY0+4GVxgnCpcjoz7wLtZCbaxg5NUYSzdWjLlFGfzkv2nh0fs5yyOTelf+njFTSnhES4xKSHsYBfnObIc4SY2ZKYzRzjEM25LCQ+F+r2VEvaEjpNNirDClobNOkXYwSoeSgkJX1PO280WVuL/0MbCb6F+L02EqawJtWxZHH4B2wwjjxrYSYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7F12183364D0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"data/tests/25784885.png\").resize((28, 28)).convert('RGBA')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b, a = img.split()\n",
    "img = np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(image, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./model/mnist_cnn.pth\"))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_transform(image)\n",
    "inputs = inputs[None, ...]\n",
    "inputs = inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(output.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-51c1aa294073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as albu\n",
    "\n",
    "\n",
    "IMG_DIR = '../訓練用画像/tranings/1/01798437.png'\n",
    "\n",
    "\n",
    "img = cv2.imread(IMG_DIR + 'image.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_origin, = img.copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes[0].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
