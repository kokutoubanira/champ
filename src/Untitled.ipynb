{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import QMNIST\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Dropout2d(p=0.20)\n",
    "            )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.25),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            #全結合層\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    " \n",
    "\n",
    "    def forward(self, x):  \n",
    "\n",
    "        out = self.cnn1(x)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.cnn3(out)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    #初期設定\n",
    "    #GPUが使えるか確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス\", device)\n",
    "    #モデルをGPUへ\n",
    "    net.to(device)\n",
    "    #ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        #epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train() #モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval() #モデルを検証モードに\n",
    "            epoch_loss = 0.0 #epochの損失0\n",
    "            epoch_corrects = 0 #epochの正解数\n",
    "            #データローダーからミニバッチを取り出すループ\n",
    "            for inputs, labels in tqdm(dataloders_dict[phase]):\n",
    "                #optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "                #順伝搬(forward)計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)#損失を計算\n",
    "                    _, preds = torch.max(outputs, 1) #ラベルを予測\n",
    "                    #訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    #イテレーション結果の計算\n",
    "                    #lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    #正解の合計数を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            #epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloders_dict[phase].dataset)\n",
    "            print('{} Loss:{:.4f} Acc: {:.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "            if phase == 'train':\n",
    "                train_acc_list.append(epoch_acc)\n",
    "                train_loss_list.append(epoch_loss)\n",
    "            else:\n",
    "                val_acc_list.append(epoch_acc)\n",
    "                val_loss_list.append(epoch_loss)\n",
    "    return val_loss_list,train_loss_list, val_acc_list, train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import os.path as osp\n",
    "import glob\n",
    "\n",
    "\n",
    "#入力画像の処理を行う\n",
    "#訓練時と推論時で処理が異なる\n",
    "\n",
    "class ImageTransform():\n",
    "\n",
    "    def __init__(self, resize):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                # transforms.RandomRotation(degrees=20), #ランダムに回転\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize), #リサイズ\n",
    "                transforms.ToTensor(), #テンソルに変換\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        \"\"\"\n",
    "        pahes:'train' or 'val'\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)\n",
    "\n",
    "class testDataset(data.Dataset):\n",
    "    '''\n",
    "    file_list : リスト\n",
    "        画像パス\n",
    "    transform: object\n",
    "        前処理クラスのインスタンス\n",
    "    phase : 学習化テストか設定する\n",
    "    '''\n",
    "    def __init__(self,transform=None, phase='val'):\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.CenterCrop(28),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, ), (0.5, ))\n",
    "                         ])\n",
    "        self.phase = phase#train or val の指定\n",
    "\n",
    "        rootpath = \"./data/tranings/\"\n",
    "        target_path = osp.join(rootpath+'**/*.png')\n",
    "    \n",
    "        path_list = []\n",
    "\n",
    "        for path in glob.glob(target_path):\n",
    "            path_list.append(path)\n",
    "\n",
    "        self.file_list = path_list\n",
    "\n",
    "    def __len__(self):\n",
    "        #画像の枚数を返す\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のTensor形式のデータとラベルの取得\n",
    "        '''\n",
    "        #index番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        label = img_path[16]\n",
    "\n",
    "        img = Image.open(img_path).convert('RGBA')\n",
    "        r, g, b, a = img.split()\n",
    "        img = np.asarray(a)\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        img_transformed = self.transform(\n",
    "            img\n",
    "        )\n",
    "\n",
    "        label = torch.tensor(int(label), dtype=torch.int64)\n",
    "        \n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス cuda:0\n",
      "Epoch 1/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5459ae9fcd42d9bbae373be55d8f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.8280 Acc: 0.6883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ae8ed4fb684fc38bcc0d61e5f4230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.8717 Acc: 0.7460\n",
      "Epoch 2/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7136bf4b93448d293869ca9873e6066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.5431 Acc: 0.9409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025bab660a4342cbacbb2c3996125ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.6330 Acc: 0.8470\n",
      "Epoch 3/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c888647298be474f8462185efcf19482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.5119 Acc: 0.9612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df32e732fc8149c1a1697eebbebbf97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.6077 Acc: 0.8690\n",
      "Epoch 4/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ad9acbd6c04ef4a68c0e4dffe09f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.5021 Acc: 0.9675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc2f57e7ea94429b9991153c02f11eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5994 Acc: 0.8730\n",
      "Epoch 5/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0256226154d4a4eb9c4174a4f49f8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4963 Acc: 0.9716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ccea77c3c144a2b55c87c9fb41668f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5805 Acc: 0.8860\n",
      "Epoch 6/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422452c0ba1f4f79b66d0b260ab972d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4919 Acc: 0.9748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c81322be4ae429faae2cddd90b666a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5680 Acc: 0.9050\n",
      "Epoch 7/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97555c2b24648e68b12488d825a152d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4893 Acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8b801f9a5a4ed085dfdbdc3db30cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5654 Acc: 0.9030\n",
      "Epoch 8/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9519c66e3fe24ce8b91ed855ec3f9ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4869 Acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e0bceba3044200beb29db7c09760a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5597 Acc: 0.9120\n",
      "Epoch 9/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b418de5b6a5941bfa2af2774f1166ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4857 Acc: 0.9788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d447e1a40ad4dda8284bb5120edcb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5670 Acc: 0.9020\n",
      "Epoch 10/10\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be840d9b8e894e2bac3657014df1cfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss:1.4842 Acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bddacc9d86c4a7f985a2b99872fd2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss:1.5640 Acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)  \n",
    "np.random.seed(seed)  \n",
    "# PyTorch のRNGを初期化  \n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "rotation_range=10\n",
    "zoom_range = 0.10\n",
    "width_shift_range=0.1 \n",
    "height_shift_range=0.1\n",
    "train_transform = transforms.Compose([\n",
    "#      transforms.Resize(36)\n",
    "#      transforms.RandomCrop(28),\n",
    "     transforms.RandomAffine(degrees=rotation_range, translate=(width_shift_range, height_shift_range), \n",
    "    scale=(1 - zoom_range, 1 + zoom_range)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))\n",
    "     ])\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize(32)\n",
    "#      transforms.CenterCrop(28),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, ), (0.5, ))\n",
    "#      ])\n",
    "\n",
    "\n",
    "trainset = QMNIST(root='./',\n",
    "                 train=True,\n",
    "                 download=True,\n",
    "                 transform=train_transform)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=1024,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)\n",
    "testloader =  torch.utils.data.DataLoader(testDataset(), batch_size = 32, shuffle=False)\n",
    "\n",
    "dataloders_dict = {\"train\": trainloader, \"val\": testloader}\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "val_loss, train_loss, val_acc, train_acc = train_model(model, dataloders_dict, criterion, optimizer, num_epochs=10)\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAA6UlEQVR4nO3Vv0pDMRSA8Z/2glTBxQ4OvoBrURTa2ckn8LF8Cx0cXZwcpTi6uOjk4CCVIuJ/h9xScUpyaehwP8gSTvIl55ATWloWnaXIuC4OsI6feu4TV7ibw7kM8IVrjOrxhOPUjarIuBXcY0+4GVxgnCpcjoz7wLtZCbaxg5NUYSzdWjLlFGfzkv2nh0fs5yyOTelf+njFTSnhES4xKSHsYBfnObIc4SY2ZKYzRzjEM25LCQ+F+r2VEvaEjpNNirDClobNOkXYwSoeSgkJX1PO280WVuL/0MbCb6F+L02EqawJtWxZHH4B2wwjjxrYSYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=28x28 at 0x7F12183364D0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"data/tests/25784885.png\").resize((28, 28)).convert('RGBA')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b, a = img.split()\n",
    "img = np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(image, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./model/mnist_cnn.pth\"))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_transform(image)\n",
    "inputs = inputs[None, ...]\n",
    "inputs = inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(output.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
